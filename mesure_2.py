import numpy as np
import librosa
import soundfile as sf
import matplotlib.pyplot as plt
from scipy.signal import correlate


def calculate_snr(y):
    # –ù–∞–π–¥—ë–º —É—á–∞—Å—Ç–∫–∏ —Å —Ä–µ—á—å—é
    intervals = librosa.effects.split(y)

    # –°–æ–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —É—á–∞—Å—Ç–∫–∏ —Å —Ä–µ—á—å—é
    y_speech = librosa.effects.remix(y, intervals)

    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω–µ
    min_len = min(len(y), len(y_speech))
    y = y[:min_len]
    y_speech = y_speech[:min_len]

    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π —à—É–º = —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º –∏ "—Ä–µ—á–µ–≤—ã–º–∏" —É—á–∞—Å—Ç–∫–∞–º–∏
    noise_estimate = y - y_speech

    signal_power = np.mean(y_speech ** 2)
    noise_power = np.mean(noise_estimate ** 2)

    snr = 10 * np.log10(signal_power / (noise_power + 1e-10))
    return snr


def spectral_flatness(y, sr):
    S = np.abs(librosa.stft(y))
    flatness = librosa.feature.spectral_flatness(S=S)
    return np.mean(flatness)


def estimate_echo(y, sr, min_delay_ms=50, threshold_ratio=0.2):
    autocorr = correlate(y, y, mode='full')
    autocorr = autocorr[len(autocorr) // 2:]  # —Ç–æ–ª—å–∫–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–¥–µ—Ä–∂–∫–∏

    min_samples = int(sr * (min_delay_ms / 1000.0))

    main_peak = autocorr[0]
    search_area = autocorr[min_samples:]

    peak_value = np.max(search_area)
    peak_index = np.argmax(search_area) + min_samples

    if peak_value > main_peak * threshold_ratio:
        echo_delay_time = peak_index / sr
    else:
        echo_delay_time = 0.0  # —ç—Ö–æ –Ω–µ –≤—ã—Ä–∞–∂–µ–Ω–æ

    return echo_delay_time, autocorr


def analyze_audio(file_path):
    y, sr = librosa.load(file_path, sr=None)

    snr_value = calculate_snr(y)
    flatness_value = spectral_flatness(y, sr)
    echo_delay, autocorr = estimate_echo(y, sr)

    print(f"[üìä] –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ '{file_path}':")
    # print(f" - –û—Ü–µ–Ω–∫–∞ SNR (—Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª/—à—É–º): {snr_value:.2f} –¥–ë")
    print(f" - –°—Ä–µ–¥–Ω—è—è —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–∞—è –ø–ª–æ—Å–∫–æ—Å—Ç–Ω–æ—Å—Ç—å: {flatness_value:.4f}")
    print(f" - –≠—Ö–æ –∑–∞–¥–µ—Ä–∂–∫–∞ (–ø—Ä–∏–±–ª.): {echo_delay:.3f} —Å–µ–∫")

    # # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
    # plt.figure(figsize=(10, 4))
    # plt.plot(np.arange(len(autocorr)) / sr, autocorr)
    # plt.title("–ê–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è (–¥–ª—è –æ—Ü–µ–Ω–∫–∏ —ç—Ö–∞)")
    # plt.xlabel("–ó–∞–¥–µ—Ä–∂–∫–∞ (—Å–µ–∫)")
    # plt.ylabel("–ê–º–ø–ª–∏—Ç—É–¥–∞")
    # plt.grid(True)
    # plt.show()


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    audio_file = "with_echo.wav"  # –∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Å–≤–æ–π —Ñ–∞–π–ª
    print(audio_file)
    analyze_audio(audio_file)

    audio_file = "processed_output.wav"  # –∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Å–≤–æ–π —Ñ–∞–π–ª
    print(audio_file)
    analyze_audio(audio_file)
